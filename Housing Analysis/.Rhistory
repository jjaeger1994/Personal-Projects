summary(ModelSteamData)
ModelSteamData <- lm(formula = Tot.Reviews ~ PositiveNegativeRatio + Price.Hr + Listed.Playtime, data = SteamReviewerDF)
summary(ModelSteamData)
ModelSteamData <- lm(formula = Tot.Reviews ~ PositiveNegativeRatio + Listed.Playtime, data = SteamReviewerDF)
summary(ModelSteamData)
ModelSteamData <- lm(formula = Tot.Reviews ~ Listed.Playtime, data = SteamReviewerDF)
summary(ModelSteamData)
ModelSteamData <- lm(formula = Tot.Reviews ~ Listed.Playtime + Price, data = SteamReviewerDF)
summary(ModelSteamData)
ModelSteamData <- lm(formula = Tot.Reviews ~ Listed.Playtime + Price + PositveNegativeRatio, data = SteamReviewerDF)
ModelSteamData <- lm(formula = Tot.Reviews ~ Listed.Playtime + Price + PositiveNegativeRatio, data = SteamReviewerDF)
summary(ModelSteamData)
Poppy <- expand_grid(
Listed.Platime = 0.5
Price = 9.99
Poppy <- expand_grid(
Listed.Playtime = 0.5
Price = 9.99
Poppy <- expand_grid(
ListedPlaytime = 0.5
Price = 9.99
Poppy <- expand_grid(
Listed.Playtime = 0.5,
Price = 9.99,
PositiveNegativeRatio = 2
)
Poppy <- expand.grid(
Listed.Playtime = 0.5,
Price = 9.99,
PositiveNegativeRatio = 2
)
Tot.ReviewPoppy <- predict(ModelSteamData, Poppy)
Tot.ReviewPoppy
ModelSteamData <- lm(formula = Tot.Reviews ~ Listed.Playtime + Price + PositiveNegativeRatio + 0, data = SteamReviewerDF)
summary(ModelSteamData)
Poppy <- expand.grid(
Listed.Playtime = 0.5,
Price = 9.99,
PositiveNegativeRatio = 2
)
Tot.ReviewPoppy <- predict(ModelSteamData, Poppy)
Tot.ReviewPoppy
seq <- 1:dim(SteamReviewerDF)[1]
ranIndex <- sample(seq)
h <- (dim(SteamReviewerDF)[1] - 0)/5
trainingDF <- slice(trainingDF, ranIndex[1:(4*h)])
seq <- 1:dim(SteamReviewerDF)[1]
ranIndex <- sample(seq)
h <- (dim(SteamReviewerDF)[1] - 0)/5
trainingDF <- slice(SteamReviewerDF, ranIndex[1:(4*h)])
testingDF <- slice(SteamReviewerDF, ranIndex[4*h +1:dim(trainingDF)[1]])
seq <- 1:dim(SteamReviewerDF)[1]
ranIndex <- sample(seq)
h <- (dim(SteamReviewerDF)[1] - 0)/5
trainingDF <- slice(SteamReviewerDF, ranIndex[1:(4*h)])
testingDF <- slice(SteamReviewerDF, ranIndex[4*h +1:dim(trainingDF)[1]])
ModelReviewer <- lm(formula = Tot.Reviews ~ Comments + log(Subscriber_count..Million.) + log(YT_Views), data = trainingDF)
summary(ModelReviewer)
ModelReviewerReduced <- lm(formula = Tot.Reviews ~ log(YT_Views), data = trainingDF)
summary(ModelReviewerReduced)
ModelSteamData <- lm(formula = Tot.Reviews ~ Listed.Playtime + Price + PositiveNegativeRatio, data = trainingDF)
summary(ModelSteamData)
Poppy <- expand.grid(
Listed.Playtime = 0.5,
Price = 9.99,
PositiveNegativeRatio = 2
)
Tot.ReviewPoppy <- predict(ModelSteamData, Poppy)
Tot.ReviewPoppy
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
SteamReviewerDF <- read.csv("ReviewerData.csv", header = TRUE)
str(SteamReviewerDF)
SteamReviewerDF %>%
ggplot(aes(x = YT_Views)) +
geom_histogram()
SteamReviewerDF %>%
ggplot(aes(x = log(YT_Views))) +
geom_histogram()
SteamReviewerDF <- SteamReviewerDF %>%
mutate(PositiveNegativeRatio = Positive/ Negative)
seq <- 1:dim(SteamReviewerDF)[1]
ranIndex <- sample(seq)
h <- (dim(SteamReviewerDF)[1] - 0)/5
trainingDF <- slice(SteamReviewerDF, ranIndex[1:(4*h)])
testingDF <- slice(SteamReviewerDF, ranIndex[4*h +1:dim(trainingDF)[1]])
CombinedModel <- lm(formula = Tot.Reviews ~ log(YT_Views) + Listed.Playtime + Price + PositiveNegativeRatio, data = trainingDF)
ModelReviewer <- lm(formula = Tot.Reviews ~ Comments + log(Subscriber_count..Million.) + log(YT_Views), data = trainingDF),
ModelReviewer <- lm(formula = Tot.Reviews ~ Comments + log(Subscriber_count..Million.) + log(YT_Views), data = trainingDF)
summary(ModelReviewer)
ModelReviewerReduced <- lm(formula = Tot.Reviews ~ log(YT_Views), data = trainingDF)
CombinedModel <- lm(formula = Tot.Reviews ~ log(YT_Views) + Listed.Playtime + Price + PositiveNegativeRatio, data = trainingDF)
summary(CombinedModel)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
SteamReviewerDF <- read.csv("ReviewerData.csv", header = TRUE)
str(SteamReviewerDF)
SteamReviewerDF %>%
ggplot(aes(x = YT_Views)) +
geom_histogram()
SteamReviewerDF %>%
ggplot(aes(x = log(YT_Views))) +
geom_histogram()
SteamReviewerDF <- SteamReviewerDF %>%
mutate(PositiveNegativeRatio = Positive/ Negative)
seq <- 1:dim(SteamReviewerDF)[1]
ranIndex <- sample(seq)
h <- (dim(SteamReviewerDF)[1] - 0)/5
trainingDF <- slice(SteamReviewerDF, ranIndex[1:(4*h)])
testingDF <- slice(SteamReviewerDF, ranIndex[4*h +1:dim(trainingDF)[1]])
CombinedModel <- lm(formula = Tot.Reviews ~ log(YT_Views) + Listed.Playtime + Price + PositiveNegativeRatio, data = trainingDF)
summary(CombinedModel)
ModelReviewer <- lm(formula = Tot.Reviews ~ Comments + log(Subscriber_count..Million.) + log(YT_Views), data = trainingDF)
summary(ModelReviewer)
ModelReviewerReduced <- lm(formula = Tot.Reviews ~ log(YT_Views), data = trainingDF)
summary(ModelReviewerReduced)
ModelSteamData <- lm(formula = Tot.Reviews ~ Listed.Playtime + Price + PositiveNegativeRatio, data = trainingDF)
summary(ModelSteamData)
Poppy <- expand.grid(
Listed.Playtime = 0.5,
Price = 9.99,
PositiveNegativeRatio = 2
)
Tot.ReviewPoppy <- predict(ModelSteamData, Poppy)
Tot.ReviewPoppy
knitr::opts_chunk$set(echo = TRUE)
typeof(DonationsDF.sf)
knitr::opts_chunk$set(echo = TRUE)
suppressMessages(library(dplyr))
library(tidyr)
library(ggplot2)
library(sf)
suppressMessages(library(tigris))
options(tigris_use_cache = TRUE)
library(stringr)
library(maps)
library(scales)
library(viridisLite)
DonationsDF <- read.csv("D:\\Josh\\Documents\\Personal\\Second Chance\\Geo\\Donations by Zip 2022-06-28.csv")
DonationsDF <- rename(DonationsDF, ZIP = Pref..ZIP.Postal.Code)
DonationsDF <- drop_na(DonationsDF, ZIP)
DonationsDF <- separate(DonationsDF,col = ZIP ,sep = "-", into = c("mainZip", "ZipTail"))
DonationsDF <- DonationsDF[DonationsDF$Constituent.Type == "Individual", ]
DonationsDF$TotalDonated <- DonationsDF$X2022...TG.Amount + DonationsDF$X2021...TG.Amount + DonationsDF$X2020...TG.Amount + DonationsDF$X2019...TG.Amount + DonationsDF$X2018...TG.Amount
DonationsDF <- DonationsDF %>%
group_by(mainZip) %>%
summarise(totalGift = sum(TotalDonated)) %>%
arrange(desc(totalGift))
DonationsDF$mainZip <- str_extract(DonationsDF$mainZip,"(\\d{5})")
head(DonationsDF, 10)
sf_use_s2(FALSE)
geo <- st_as_sf(zctas(cb = TRUE, starts_with = c("63","64","65")))
states <- st_as_sf(states(cb = TRUE))
countiesMO <- st_as_sf(counties(cb = TRUE, state = "29"))
cities <- us.cities
geo$ZCTA5CE20 <- str_trim(geo$ZCTA5CE20)
DonationsDF.sf <- left_join(geo, DonationsDF, by= c("GEOID20" = "mainZip"))
DonationsDF.sf %>%
arrange(desc(totalGift)) %>%
head(10)
DonationsDF.sf <- filter(DonationsDF.sf, !st_is_empty(geometry))
DonationsDF.sf <- st_make_valid(DonationsDF.sf)
DonationsDF.sf <- filter(DonationsDF.sf, DonationsDF.sf$totalGift > 0)
typeof(DonationsDF.sf)
typeof(DonationsDF.sf)
typeof(geo)
typeof(geo)
sf_use_s2(FALSE)
geo <- st_as_sf(zctas(cb = TRUE, starts_with = c("63","64","65")))
states <- st_as_sf(states(cb = TRUE))
countiesMO <- st_as_sf(counties(cb = TRUE, state = "29"))
cities <- us.cities
typeof(geo)
class(geo)
class(DonationsDF.sf)
typeof(geo)
class(DonationsDF.sf)
class(geo)
knitr::opts_chunk$set(echo = TRUE)
suppressMessages(library(dplyr))
library(tidyr)
library(ggplot2)
library(sf)
suppressMessages(library(tigris))
options(tigris_use_cache = TRUE)
library(stringr)
library(maps)
library(scales)
library(viridisLite)
DonationsDF <- read.csv("D:\\Josh\\Documents\\Personal\\Second Chance\\Geo\\Donations by Zip 2022-06-28.csv")
DonationsDF <- rename(DonationsDF, ZIP = Pref..ZIP.Postal.Code)
DonationsDF <- drop_na(DonationsDF, ZIP)
DonationsDF <- separate(DonationsDF,col = ZIP ,sep = "-", into = c("mainZip", "ZipTail"))
DonationsDF <- DonationsDF[DonationsDF$Constituent.Type == "Individual", ]
DonationsDF$TotalDonated <- DonationsDF$X2022...TG.Amount + DonationsDF$X2021...TG.Amount + DonationsDF$X2020...TG.Amount + DonationsDF$X2019...TG.Amount + DonationsDF$X2018...TG.Amount
DonationsDF <- DonationsDF %>%
group_by(mainZip) %>%
summarise(totalGift = sum(TotalDonated)) %>%
arrange(desc(totalGift))
DonationsDF$mainZip <- str_extract(DonationsDF$mainZip,"(\\d{5})")
head(DonationsDF, 10)
sf_use_s2(FALSE)
geo <- st_as_sf(zctas(cb = TRUE, starts_with = c("63","64","65")))
states <- st_as_sf(states(cb = TRUE))
countiesMO <- st_as_sf(counties(cb = TRUE, state = "29"))
cities <- us.cities
class(geo)
geo$ZCTA5CE20 <- str_trim(geo$ZCTA5CE20)
DonationsDF.sf <- left_join(geo, DonationsDF, by= c("GEOID20" = "mainZip"))
DonationsDF.sf %>%
arrange(desc(totalGift)) %>%
head(10)
DonationsDF.sf <- filter(DonationsDF.sf, !st_is_empty(geometry))
DonationsDF.sf <- st_make_valid(DonationsDF.sf)
DonationsDF.sf <- filter(DonationsDF.sf, DonationsDF.sf$totalGift > 0)
class(DonationsDF.sf)
class(geo)
MO <- states[states$NAME == "Missouri",]
MOcities <- cities[cities$country.etc == "MO", ]
ggplot(data= DonationsDF.sf) +
geom_boxplot(aes(y=log(totalGift)))
MOPlot <- ggplot(data = DonationsDF.sf) +
geom_sf(data = MO) +
geom_sf(color= NA,aes(fill= totalGift), position= "dodge") +
##geom_sf_label(aes(label = totalGift)) +
scale_fill_viridis_c(labels= dollar, na.value = "light grey", trans= "log10",  option="magma") +
geom_sf(data = countiesMO, alpha= 0.1) +
geom_point(data = MOcities, aes(x=long, y=lat) ) +
coord_sf() +
theme_void()
MOPlot +
labs(title = "Missouri")
MOPlot +
coord_sf(xlim = c(-94,-92),ylim = c(38,40)) +
labs(title= "Central MO") +
geom_text(data = MOcities, aes(x=long, y=lat, label=name), size= 3, hjust=1, vjust=1)
MOPlot +
coord_sf(xlim = c(-91,-90),ylim = c(38,39)) +
labs(title= "St. Louis Region")
install.packages("https://cran.r-project.org/src/contrib/Archive/rlang/rlang_0.4.10.tar.gz", repos = NULL, type="source")
install.packages("https://cran.r-project.org/src/contrib/Archive/rlang/rlang_1.0.6.tar.gz", repos = NULL, type="source")
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
library(dplyr)
install.packages("dplyr")
library(rlang)
install.packages("rlang")
library(dplyr)
library(tsibble)
library(ggplot2)
library(lubridate)
library(tibble)
library(tsibbledata)
library(feasts)
library(fable)
us_home_price <- read.csv("RawData/MSPUS.csv")
setwd("C:/Users/Josh/Documents/GitHub/Personal-Projects")
us_home_price <- read.csv("RawData/MSPUS.csv")
setwd("C:/Users/Josh/Documents/GitHub/Personal-Projects/RawData")
us_home_price <- read.csv("MSPUS.csv")
us_home_sales <- read.csv("RawData/HSN1F.csv")
setwd("C:/Users/Josh/Documents/GitHub/Personal-Projects")
setwd("C:/Users/Josh/Documents/GitHub/Personal-Projects/Housing Analysis")
us_home_price <- read.csv("RawData/MSPUS.csv")
head(us_home_price)
us_home_price <- rename(us_home_price, Price = MSPUS)
library(dplyr)
library(tsibble)
library(ggplot2)
library(lubridate)
library(tibble)
library(tsibbledata)
library(feasts)
library(fable)
us_home_price <- read.csv("RawData/MSPUS.csv")
head(us_home_price)
us_home_price <- rename(us_home_price, Price = MSPUS)
us_home_price <- us_home_price %>%
mutate(DATE = yearquarter(DATE)) %>%
as_tsibble(index=DATE)
ggplot(us_home_price) +
geom_line(aes(x=DATE, y=Price)) +
labs(title = "Median US House Price", y= "Price", x=NULL) +
theme_minimal()
us_home_price %>%
model(STL(Price ~
trend() +
season(window="periodic"))) %>%
components() %>%
autoplot()
us_home_sales <- read.csv("RawData/HSN1F.csv")
head(us_home_sales)
us_home_sales <- us_home_sales %>%
rename(Sales = HSN1F) %>%
mutate(DATE = yearmonth(DATE)) %>%
as_tsibble(index=DATE)
autoplot(us_home_sales,Sales) +
theme_minimal() +
labs(title = "US Home Sales", x=NULL)
us_home_sales %>%
model(
STL(Sales ~
trend() +
season())) %>%
components() %>%
autoplot()
suppressWarnings(library(dplyr))
suppressWarnings(library(tsibble))
suppressWarnings(library(ggplot2))
suppressWarnings(library(lubridate))
suppressWarnings(library(tibble))
suppressWarnings(library(tsibbledata))
suppressWarnings(library(feasts))
suppressWarnings(library(fable))
us_home_price %>%
model(STL(Price ~
trend() +
season())) %>%
components() %>%
autoplot()
head(us_cpi)
us_cpi <- read.csv("RawData/CPIAUCNS.csv")
head(us_cpi)
us_cpi <- read.csv("RawData/CPIAUCNS.csv")
head(us_cpi)
us_cpi[1]
us_cpi <- read.csv("RawData/CPIAUCNS.csv")
head(us_cpi)
us_cpi[2,1]
us_cpi[1,2]
us_cpi <- read.csv("RawData/CPIAUCNS.csv")
head(us_cpi)
us_cpi <- us_cpi %>%
mutate(adjustedcpi = CPIAUCNS/us_cpi[1,2]
us_cpi <- read.csv("RawData/CPIAUCNS.csv")
head(us_cpi)
us_cpi <- us_cpi %>%
mutate(adjustedcpi = CPIAUCNS/us_cpi[1,2])
us_cpi <- read.csv("RawData/CPIAUCNS.csv")
head(us_cpi)
us_cpi <- us_cpi %>%
mutate(adjustedcpi = CPIAUCNS/us_cpi[1,2])
head(us_cpi)
us_cpi <- us_cpi %>%
mutate(DATE = yearquarter(DATE)) %>%
as_tsibble(index=DATE)
us_cpi <- us_cpi %>%
mutate(DATE = yearquarter(DATE)) %>%
as_tsibble(index=DATE)
inflation_prices <- inner_join(us_home_price, us_cpi, by= DATE )
us_cpi <- us_cpi %>%
mutate(DATE = yearquarter(DATE)) %>%
as_tsibble(index=DATE)
inflation_prices <- inner_join(us_home_price, us_cpi, by= c("DATE" ="DATE"))
head(inflation_prices)
inflation_prices <- mutate(adjusted_price = Price/adjustedcpi)
us_cpi <- us_cpi %>%
mutate(DATE = yearquarter(DATE)) %>%
as_tsibble(index=DATE)
inflation_prices <- inner_join(us_home_price, us_cpi, by= c("DATE" ="DATE"))
head(inflation_prices)
inflation_prices <- mutate(adjusted_price = Price/adjustedcpi)
us_cpi <- us_cpi %>%
mutate(DATE = yearquarter(DATE)) %>%
as_tsibble(index=DATE)
inflation_prices <- inner_join(us_home_price, us_cpi, by= c("DATE" ="DATE"))
head(inflation_prices)
inflation_prices <- mutate(inflation_prices, adjusted_price = Price/adjustedcpi)
ggplot(inflation_prices) +
geom_line(aes(x=DATE, y=adjusted_price)) +
labs(title = "Median US House Price", y= "Price", x=NULL) +
theme_minimal()
ggplot(inflation_prices) +
geom_line(aes(x=DATE, y=adjusted_price)) +
labs(title = "Median US House Price", y= "Inflation Adjusted Price", x=NULL) +
theme_minimal()
ggplot(inflation_prices) +
geom_line(aes(x=DATE, y=adjusted_price)) +
labs(title = "Median US House Price (Inflation Adjusted)", y= "Inflation Adjusted Price", x=NULL) +
theme_minimal()
inflation_prices %>%
model(STL(Price ~
trend() +
season())) %>%
components() %>%
autoplot()
inflation_prices %>%
model(STL(adjusted_price ~
trend() +
season())) %>%
components() %>%
autoplot()
us_mortgage_rates <- read.csv("RawData/MORGAGE30US.csv") %>%
mutate(DATE = yearquarter(DATE)) %>%
as_tsibble(index=DATE)
us_mortgage_rates <- read.csv("RawData/MORTGAGE30US.csv") %>%
mutate(DATE = yearquarter(DATE)) %>%
as_tsibble(index=DATE)
us_mortgage_rates <- read.csv("RawData/MORTGAGE30US.csv") %>%
head()
mutate(DATE = yearquarter(DATE)) %>%
as_tsibble(index=DATE)
us_mortgage_rates <- read.csv("RawData/MORTGAGE30US.csv") %>%
head()
mutate(DATE = yearquarter(DATE)) %>%
as_tsibble(index=DATE)
us_mortgage_rates <- read.csv("RawData/MORTGAGE30US.csv") %>%
head()
read.csv("RawData/MORTGAGE30US.csv") %>%
head()
us_mortgage_rates <- read.csv("RawData/MORTGAGE30US.csv") %>%
mutate(DATE = yearquarter(DATE)) %>%
as_tsibble(index=DATE)
read.csv("RawData/MORTGAGE30US.csv")
us_mortgage_rates <- read.csv("RawData/MORTGAGE30US.csv") %>%
mutate(DATE = yearmonth(DATE)) %>%
as_tsibble(index=DATE)
model <- left_join(us_home_sales,us_mortgage_rates, by= c("DATE" = "DATE"))
head(model)
fit <- model %>%
model(
rate_lag = ARIMA(Sales ~ pdq(d = 0) + lag(MORTGAGE30US))
)
fit %>%
forecast(model) %>%
autoplot(model)
model_future <- new_data(model, 20) %>%
mutate(MORTGAGE30US = 8.5)
fit %>%
forecast(model_future) %>%
autoplot(model)
model_future <- new_data(model, 20) %>%
mutate(MORTGAGE30US = 8.5)
fit %>%
forecast(model_future)
fit <- model %>%
model(
ARIMA(Sales ~ pdq(d = 0) + lag(MORTGAGE30US))
)
model_future <- new_data(model, 20) %>%
mutate(MORTGAGE30US = 8.5)
fit %>%
forecast(model_future)
fit <- model %>%
model(
ARIMA(Sales ~ pdq(d = 0) + lag(MORTGAGE30US))
)
head(fit)
fit <- model %>%
model(
ARIMA(Sales ~ pdq(d = 0) + lag(MORTGAGE30US))
)
model_future <- new_data(model, 20) %>%
mutate(MORTGAGE30US = 8.5)
model_future <- new_data(model, 20) %>%
mutate(MORTGAGE30US = 8.5)
head(model_future)
fit %>%
forecast(model_future)
fit <- model %>%
model(
ARIMA(Sales ~ pdq(d = 0) + lag(MORTGAGE30US))
)
report(fit)
fit <- model %>%
model(ARIMA(Sales ~ pdq(d = 0) + lag(MORTGAGE30US))) %>%
forecast()
fit <- model %>%
model(ARIMA(Sales ~ pdq(d = 0) + lag(MORTGAGE30US))) %>%
forecast()
fit <- model %>%
model(ARIMA(Sales ~ pdq(d = 0) + MORTGAGE30US)) %>%
forecast()
model_data <- left_join(us_home_sales,us_mortgage_rates, by= c("DATE" = "DATE"))
head(model_data)
fit <- model_data %>%
model(ARIMA(Sales ~ pdq(d = 0) + MORTGAGE30US)) %>%
forecast()
fit <- model_data %>%
model(ARIMA(Sales ~ pdq(d = 0))) %>%
forecast()
model_data <- left_join(us_home_sales,us_mortgage_rates, by= c("DATE" = "DATE"))
model_data
fit <- model_data %>%
model(ARIMA(Sales ~ pdq(d = 0)))
report(fit)
model_future <- new_data(model, 20) %>%
mutate(MORTGAGE30US = 8.5)
forecast(model_future)
model_future <- new_data(model, 20) %>%
mutate(MORTGAGE30US = 8.5)
fit %>%
forecast(model_future)
model_future <- new_data(model, 20) %>%
mutate(MORTGAGE30US = 8.5)
fit %>%
fable::forecast(model_future)
model_future <- new_data(model, 20) %>%
mutate(MORTGAGE30US = 8.5)
fit %>%
forecast::forecast(model_future)
model_future <- new_data(model, 20) %>%
mutate(MORTGAGE30US = 8.5)
fit %>%
fable::forecast(model_future)
model_future <- new_data(model, 20) %>%
mutate(MORTGAGE30US = 8.5)
fit %>%
fabletools::forecast(model_future)
